2025-05-12 05:00:37.053556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1747051237.079172 2994711 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1747051237.086767 2994711 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1747051237.107480 2994711 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1747051237.107552 2994711 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1747051237.107556 2994711 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1747051237.107560 2994711 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-05-12 05:00:37.113365: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.37s/it]
Using cache found in /local3/minhtr/.cache/torch/hub/intel-isl_MiDaS_master
Using cache found in /local3/minhtr/.cache/torch/hub/intel-isl_MiDaS_master
Warming up PyWSD (takes ~10 secs)... took 6.877618789672852 secs.
VISION BACKBONE USE GRADIENT CHECKPOINTING:  False
LANGUAGE BACKBONE USE GRADIENT CHECKPOINTING:  False
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
EARLY FUSION ON, USING MHA-B
Subset requested. Only selecting from 0 to 1500
            video  ...                                                 a3
0     Cm73ma6Ibcs  ...                                               1633
1     Cm73ma6Ibcs  ...                                              Rainy
2     Cm73ma6Ibcs  ...  The protagonist pushes the table aside and sta...
3     Cm73ma6Ibcs  ...  The protagonist breaks the windows with her sw...
4     Cm73ma6Ibcs  ...                                                  1
...           ...  ...                                                ...
1471  20lTg3yUrO4  ...                        Lagos Market Fire Aftermath
1472  20lTg3yUrO4  ...                           Ogbonnaya Onu dies at 72
1473  20lTg3yUrO4  ...                                              Black
1474  20lTg3yUrO4  ...                                        Peter Odili
1475  20lTg3yUrO4  ...  First, the news was introduced by the host in ...

[1476 rows x 11 columns]
  0%|          | 0/738 [00:00<?, ?it/s]Tensorizing new video. let's check RAM usage -- should be appropriately used based on the number of questions per video & batch size. This operation should not happen often.
               total        used        free      shared  buff/cache   available
Mem:           503Gi       191Gi        85Gi       5.7Gi       226Gi       303Gi
Swap:          4.0Gi       4.0Gi          0B

tensorizing /local3/minhtr/VIPER/datasets/LVBench/raw_videos/Cm73ma6Ibcs.mp4 
using cpu btw
preparations complete. original frames: 87972, original fps: 24.0, requested fps: 1, so final frame count is 3665 to be processed in batches of 2000

Decoding frames in batches:   0%|          | 0/2 [00:00<?, ?it/s][A
Decoding frames in batches:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:14<00:14, 14.06s/it][A
Decoding frames in batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 12.98s/it][ADecoding frames in batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.14s/it]
  0%|          | 0/738 [01:26<?, ?it/s]
tensorization finished with torch.Size([3665, 3, 360, 640]) and torch.uint8.
video Cm73ma6Ibcs completely finished tensorization. if no progress bar shown, this was retreived from LRU RAM cache.
video Cm73ma6Ibcs completely finished tensorization. if no progress bar shown, this was retreived from LRU RAM cache.
Prompting code gen model...
raw code generation output
['```python\ndef execute_command(video, possible_answers, query) -> [str, dict]:\n    from typing import List\n    import torch\n\n    # Initialize VideoSegment for the entire video\n    video_segment = VideoSegment(video)\n\n    # Iterate over frames in the video; since it can be long, check every 5 frames\n    for i, frame in enumerate(video_segment.frame_iterator()):\n        if i % 5 == 0:\n            # Use simple_query to search for the opening caption with a year\n            caption_query = frame.simple_query("What year appears in the opening caption?")\n            if caption_query in possible_answers:\n                answer = caption_query\n                break\n\n    return answer', '```python\ndef execute_command(video, possible_answers, query):\n    # Import necessary libraries\n    from typing import List\n    \n    # Define the possible options for the weather\n    weather_options = possible_answers\n    \n    # Create a VideoSegment for the first part of the video to check the opening weather\n    video_segment = VideoSegment(video, 0, video.shape[0] // 5)\n    \n    # Iterate over frames in the opening segment\n    for frame in video_segment.frame_iterator():\n        # Check for the best match of the weather condition\n        answer = frame.best_text_match(weather_options)\n        if answer:\n            return answer\n    \n    # Default return if nothing is found (should not happen if video contains relevant content)\n    return "Unknown"']
ABOUT TO RUN THE FOLLOWING CODE: 
def execute_command_0(video, possible_answers, query, ImagePatch, VideoSegment, llm_query, bool_to_yesno, distance, best_image_match):
    # Answer is
    from typing import List
    import torch

    # Initialize VideoSegment for the entire video
    video_segment = VideoSegment(video)

    # Iterate over frames in the video; since it can be long, check every 5 frames
    for i, frame in enumerate(video_segment.frame_iterator()):
        if i % 5 == 0:
            # Use simple_query to search for the opening caption with a year
            caption_query = frame.simple_query("What year appears in the opening caption?")
            if caption_query in possible_answers:
                answer = caption_query
                break

    return answer
ABOUT TO COMPILE # 0
ABOUT TO EXEC # 0
Traceback (most recent call last):
  File "/local3/minhtr/VIPER/VdebuggerFollowup/main_batch.py", line 98, in run_program
    result = future.result(timeout=1500)  # ‚è± 25 min timeout
  File "/local/minh/miniconda3/envs/viper-main/lib/python3.10/concurrent/futures/_base.py", line 453, in result
    self._condition.wait(timeout)
  File "/local/minh/miniconda3/envs/viper-main/lib/python3.10/threading.py", line 324, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local3/minhtr/VIPER/VdebuggerFollowup/main_batch.py", line 369, in <module>
    main()
  File "/local3/minhtr/VIPER/VdebuggerFollowup/main_batch.py", line 219, in main
    result = run_program([c, sample_id, img, possible_answers, query], queues_in, input_type)
  File "/local3/minhtr/VIPER/VdebuggerFollowup/main_batch.py", line 96, in run_program
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
  File "/local/minh/miniconda3/envs/viper-main/lib/python3.10/concurrent/futures/_base.py", line 649, in __exit__
    self.shutdown(wait=True)
  File "/local/minh/miniconda3/envs/viper-main/lib/python3.10/concurrent/futures/thread.py", line 235, in shutdown
    t.join()
  File "/local/minh/miniconda3/envs/viper-main/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/local/minh/miniconda3/envs/viper-main/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
FATAL: exception not rethrown
